# 🕷️ ウェブスクレイピングおよびブラウザ自動化ツール包括的要覧

本資料は、ウェブスクレイピングおよび自動化処理に供される主要なライブラリならびにツール群を体系化したものです。JavaScript実行の要否、処理速度、検知回避の必要性といったプロジェクト要件に基づき、最適なツール選定を行うための指針を提供します。

## 📑 目次

1. [ブラウザ自動化ツール (動的サイト・SPA向け)](#1-ブラウザ自動化ツール-動的サイトspa向け)
2. [HTTPリクエスト・解析ツール (静的サイト向け)](#2-httpリクエスト解析ツール-静的サイト向け)
3. [大規模フレームワーク (クローラー向け)](#3-大規模フレームワーク-クローラー向け)
4. [拡張・特殊用途ツール (回避・デバッグ用)](#4-拡張特殊用途ツール-回避デバッグ用)
5. [✅ 比較総括：推奨される選定指針](#5-比較総括推奨される選定指針)

---

## 1. 🖥️ ブラウザ自動化ツール (動的サイト・SPA向け)

JavaScriptによって動的に生成されるコンテンツ（React、Vue等）や、複雑な認証プロセスを伴うウェブサイトを対象とする場合に適用されるツール群です。

| 名称 | 開発元 | 言語 | 特徴・優位性 | 制限事項・課題 |
| :--- | :--- | :--- | :--- | :--- |
| **Selenium 4** | コミュニティ | Python, Java,<br>JS, C# 等 | **【業界標準】**<br>・豊富な技術情報とドキュメント<br>・主要ブラウザを網羅的にサポート<br>・Ver.4よりCDP対応で機能拡張 | ・実行速度が相対的に緩慢<br>・ドライバー管理等の環境構築に工数を要する |
| **Playwright** | Microsoft | Python, Node.js,<br>.NET, Java | **【主要推奨】**<br>・高速かつ安定した動作<br>・ブラウザバイナリの自動取得<br>・高度な自動待機 (Auto-wait) と並列実行 | ・新興技術のため、Seleniumに比べ知見が限定的<br>（急速に標準化が進行中） |
| **Puppeteer** | Google | Node.js<br>(Python版: Pyppeteer) | **【Chrome特化】**<br>・Google純正による高い安定性<br>・Chrome/Chromium制御に特化 | ・原則Chrome系のみサポート<br>・Python環境では非公式ポートが必要 |

### 🧭 選定指針

> **Pythonを用いたモダンな記述・処理速度を重視**
> 👉 **[Playwright](https://playwright.dev/)** の採用を推奨

> **情報の網羅性・既存資産の活用を重視**
> 👉 **[Selenium](https://www.selenium.dev/)** の採用が妥当

> **Node.js環境下でChromeのみを対象とする**
> 👉 **[Puppeteer](https://pptr.dev/)** の採用が適切

---

## 2. ⚡ HTTPリクエスト・解析ツール (静的サイト向け)

ブラウザを起動せず、サーバーと直接通信を行う手法です。高速処理が可能ですが、JavaScriptは実行されない点に留意が必要です。

| 名称 | 役割 | 特徴 |
| :--- | :--- | :--- |
| **Requests** | 通信 | **Python標準のHTTPライブラリ**<br>簡潔かつ明瞭な記述が可能で、圧倒的な利用実績を持つ。 |
| **Beautiful Soup 4** | 解析 | **HTML/XML解析ライブラリ**<br>構造が不完全なHTMLに対しても堅牢な解析が可能。通常、Requestsと併用される。 |
| **lxml** | 解析 | **高速解析ライブラリ**<br>C言語で記述されており、Beautiful Soupよりも高速。XPathによる指定が可能。 |

---

## 3. 🏗️ 大規模フレームワーク (クローラー向け)

| 名称 | 特徴 |
| :--- | :--- |
| **Scrapy** | **【高性能クローラー】**<br>Python製の包括的スクレイピングフレームワーク。非同期処理の実装により、数万ページ規模のデータ収集において卓越した速度を発揮する。<br>※習得には一定の学習コストを要する。 |

---

## 4. 🛡️ 拡張・特殊用途ツール (回避・デバッグ用)

| 名称 | ベース | 用途・特徴 |
| :--- | :--- | :--- |
| **Selenium-Wire** | Selenium | **【通信傍受】**<br>Seleniumにプロキシ機能を付加し、HTTPリクエスト/レスポンス（APIのJSONデータ等）の傍受・変更を可能にする。 |
| **undetected-chromedriver** | Selenium | **【Bot検知回避】**<br>Cloudflare等によるBot対策システムを回避するため、Selenium特有の識別子（フィンガープリント）を除去した改変ドライバー。 |
| **SeleniumBase** | Selenium | **【統合フレームワーク】**<br>Seleniumをラップして操作性を向上させつつ、Bot検知回避機能も統合した高機能ツール。 |
| **MechanicalSoup** | Requests | **【ブラウザ模倣】**<br>ブラウザを使わずに、RequestsとBeautiful Soupを用いてブラウザの挙動（フォーム入力やボタン操作等）を模倣する軽量ライブラリ。 |

---

## 5. ✅ 比較総括：推奨される選定指針

プロジェクトの目的に応じた最適なツールの組み合わせは以下の通りです。

1.  **簡易的なデータ抽出を迅速に行いたい**
    * 👉 **Requests + Beautiful Soup** (静的サイト最速・最軽量)

2.  **ボタン操作、認証、JS実行が必要なサイト**
    * 👉 **Playwright** (新規習得に推奨)
    * 👉 **Selenium** (日本語情報の豊富さを重視)

3.  **API通信(JSON)を直接取得したい**
    * 👉 **Selenium-Wire** (または Playwright の `page.on("response")` )

4.  **数万件規模のデータを定期的に収集したい**
    * 👉 **Scrapy** (速度と運用管理機能が不可欠)
  
5.  ## 13. 【総まとめ】Bot検知回避（ステルス化）のメソッド一覧

現代の強力なWebセキュリティ（Cloudflare, Datadome, Akamaiなど）を回避し、安全かつ安定してスクレイピングを行うための手法（メソッド）を、4つの階層に分けて網羅しました。

### レベル1：通信ヘッダーの偽装（基本）
最も基礎的な対策です。これがないと、ほぼすべてのサイトで即座に弾かれます。

* **User-Agentの偽装:** * **対策:** `requests` や `aiohttp` のヘッダーに、一般的なChromeやSafariのUser-Agent文字列を設定する。
* **完全なヘッダーの再現:** * **対策:** `Accept-Language` (言語) や `Referer` (遷移元のURL) など、実際のブラウザが送っているヘッダーを漏れなく付与する。
* **セッション（Cookie）の維持:** * **対策:** `requests.Session()` や `aiohttp.ClientSession()` を使い、サーバーから付与されたCookie（訪問者の証）を保持したまま連続アクセスする。

### レベル2：通信プロトコルの偽装（強力）
`requests` や `aiohttp` が抱える「Python特有の通信のクセ」を消し去る手法です。

* **TLS指紋（JA3）の偽装:** * **原因:** 暗号化通信の初期設定（ハンドシェイク）の順序などでPythonだとバレる。
  * **対策:** `curl_cffi` の `impersonate="chrome120"` などを使い、通信の低レイヤーから完全にブラウザのクセを模倣する。HTTP/2の指紋（HTTP2 Fingerprint）対策にも有効。

### レベル3：ブラウザ環境の偽装（最終手段）
JavaScriptの実行チェックや、ブラウザ特有の内部変数をチェックされる場合の対策です。

* **WebDriverフラグの隠蔽:** * **原因:** Selenium等を使うと `navigator.webdriver = true` という「Bot宣言」がされてしまう。
  * **対策:** `undetected-chromedriver` を使用し、ブラウザ起動時にこのフラグをバイナリレベルで削除する。
* **ブラウザ指紋（Canvas / WebGL）の回避:** * **原因:** 描画エンジンのクセやインストールされているフォントを読み取られる。
  * **対策:** Playwrightの拡張機能（`playwright-stealth`）を利用するか、商用のアンチ検出ブラウザ（AdsPowerなど）をAPI経由で操作する。
* **CAPTCHA（パズル等）の突破:**
  * **対策:** 人間の手で解くか、外部のCAPTCHA自動解決API（2Captcha, Anti-Captchaなど）をプログラムに組み込む。

### レベル4：アクセスインフラと振る舞いの偽装
どれだけ完璧にブラウザを偽装しても、アクセス元のIPや頻度が不自然だとブロックされます。

* **IPアドレスの分散（プロキシローテーション）:**
  * **原因:** 同一IPから短時間に数百回のアクセスがあると、DDOS攻撃とみなされてBANされる。
  * **対策:** 商用のローテーティング・プロキシ（アクセス毎に世界中の一般家庭のIPに切り替わるサービス）を経由させる。
* **アクセス頻度の制御（レートリミット回避）:**
  * **対策:** 非同期処理（`aiohttp`等）で並列アクセスする際は、必ず `asyncio.Semaphore` で同時接続数を絞る。
* **人間らしい「揺らぎ」の追加:**
  * **対策:** `time.sleep(random.uniform(1.5, 3.5))` のように、アクセス間隔にランダムな秒数（ジッター）を設ける。Seleniumの場合は、マウスの移動軌跡やスクロール速度にランダム性を持たせる。

---

### 💡 検知回避のクイック・チートシート

| ブロックされる原因 | 推奨されるPythonライブラリ / 手法 |
| :--- | :--- |
| 「python-requests」で弾かれる | `requests` (ヘッダーの `User-Agent` を偽装) |
| Cloudflare等のWAF（403エラー） | `curl_cffi` (TLS指紋を `impersonate` で偽装) |
| サイトがJSで描画されて真っ白 | `Playwright` または `Selenium` |
| SeleniumがBot検知で弾かれる | `undetected-chromedriver` |
| 1時間に1000回アクセスでIP BAN | `aiohttp` (非同期) + ローテーティング・プロキシ |
| CAPTCHA・パズルが出現する | 2Captcha等の外部解決サービスを利用 |

6.  **Bot検知システムによる遮断が発生する**
    * 👉 **undetected-chromedriver** または **SeleniumBase**
